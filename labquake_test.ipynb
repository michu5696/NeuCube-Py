{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ddeecf-beb3-4e07-ac81-53dd325ba13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neucube import Reservoir\n",
    "from neucube.encoder import RateEncoder, Deltav2\n",
    "from neucube.validation import Pipeline\n",
    "from neucube.sampler import SpikeCount, DeSNN\n",
    "from neucube.datamanager import DataManager\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662ae5c4-88b5-4edd-bdb1-4cbe6db6c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'source_data_path': 'example_data/labquake_source',\n",
    "            'samples_path':'example_data/labquake_samples',\n",
    "            'sampling_rate': 5000,\n",
    "            'batch_duration': 18000,\n",
    "        }\n",
    "datamanager = DataManager(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecd3687-3bee-4c0c-a7f9-d392c6c4aac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 from both systems saved to example_data/labquake_samples/sample_1.csv\n",
      "Batch 2 from both systems saved to example_data/labquake_samples/sample_2.csv\n",
      "Batch 3 from both systems saved to example_data/labquake_samples/sample_3.csv\n",
      "Batch 4 from both systems saved to example_data/labquake_samples/sample_4.csv\n",
      "Batch 5 from both systems saved to example_data/labquake_samples/sample_5.csv\n",
      "Batch 6 from both systems saved to example_data/labquake_samples/sample_6.csv\n",
      "Batch 7 from both systems saved to example_data/labquake_samples/sample_7.csv\n",
      "Batch 8 from both systems saved to example_data/labquake_samples/sample_8.csv\n",
      "Batch 9 from both systems saved to example_data/labquake_samples/sample_9.csv\n",
      "Batch 10 from both systems saved to example_data/labquake_samples/sample_10.csv\n",
      "Batch 11 from both systems saved to example_data/labquake_samples/sample_11.csv\n",
      "Batch 12 from both systems saved to example_data/labquake_samples/sample_12.csv\n",
      "Batch 13 from both systems saved to example_data/labquake_samples/sample_13.csv\n",
      "Batch 14 from both systems saved to example_data/labquake_samples/sample_14.csv\n",
      "Batch 15 from both systems saved to example_data/labquake_samples/sample_15.csv\n",
      "Batch 16 from both systems saved to example_data/labquake_samples/sample_16.csv\n",
      "Batch 17 from both systems saved to example_data/labquake_samples/sample_17.csv\n",
      "Batch 18 from both systems saved to example_data/labquake_samples/sample_18.csv\n",
      "Batch 19 from both systems saved to example_data/labquake_samples/sample_19.csv\n",
      "Batch 20 from both systems saved to example_data/labquake_samples/sample_20.csv\n",
      "Batch 21 from both systems saved to example_data/labquake_samples/sample_21.csv\n",
      "Batch 22 from both systems saved to example_data/labquake_samples/sample_22.csv\n",
      "Batch 23 from both systems saved to example_data/labquake_samples/sample_23.csv\n",
      "Batch 24 from both systems saved to example_data/labquake_samples/sample_24.csv\n",
      "Batch 25 from both systems saved to example_data/labquake_samples/sample_25.csv\n",
      "Batch 26 from both systems saved to example_data/labquake_samples/sample_26.csv\n",
      "Batch 27 from both systems saved to example_data/labquake_samples/sample_27.csv\n",
      "Batch 28 from both systems saved to example_data/labquake_samples/sample_28.csv\n",
      "Batch 29 from both systems saved to example_data/labquake_samples/sample_29.csv\n",
      "Batch 30 from both systems saved to example_data/labquake_samples/sample_30.csv\n",
      "Batch 31 from both systems saved to example_data/labquake_samples/sample_31.csv\n",
      "Batch 32 from both systems saved to example_data/labquake_samples/sample_32.csv\n",
      "Batch 33 from both systems saved to example_data/labquake_samples/sample_33.csv\n",
      "Batch 34 from both systems saved to example_data/labquake_samples/sample_34.csv\n",
      "Batch 35 from both systems saved to example_data/labquake_samples/sample_35.csv\n",
      "Batch 36 from both systems saved to example_data/labquake_samples/sample_36.csv\n",
      "Batch 37 from both systems saved to example_data/labquake_samples/sample_37.csv\n",
      "Batch 38 from both systems saved to example_data/labquake_samples/sample_38.csv\n",
      "Batch 39 from both systems saved to example_data/labquake_samples/sample_39.csv\n",
      "Batch 40 from both systems saved to example_data/labquake_samples/sample_40.csv\n",
      "Batch 41 from both systems saved to example_data/labquake_samples/sample_41.csv\n",
      "Batch 42 from both systems saved to example_data/labquake_samples/sample_42.csv\n",
      "Batch 43 from both systems saved to example_data/labquake_samples/sample_43.csv\n",
      "Batch 44 from both systems saved to example_data/labquake_samples/sample_44.csv\n",
      "Batch 45 from both systems saved to example_data/labquake_samples/sample_45.csv\n",
      "Batch 46 from both systems saved to example_data/labquake_samples/sample_46.csv\n",
      "Batch 47 from both systems saved to example_data/labquake_samples/sample_47.csv\n",
      "Batch 48 from both systems saved to example_data/labquake_samples/sample_48.csv\n",
      "Batch 49 from both systems saved to example_data/labquake_samples/sample_49.csv\n",
      "Batch 50 from both systems saved to example_data/labquake_samples/sample_50.csv\n",
      "Batch 51 from both systems saved to example_data/labquake_samples/sample_51.csv\n",
      "Batch 52 from both systems saved to example_data/labquake_samples/sample_52.csv\n",
      "Batch 53 from both systems saved to example_data/labquake_samples/sample_53.csv\n",
      "Batch 54 from both systems saved to example_data/labquake_samples/sample_54.csv\n",
      "Batch 55 from both systems saved to example_data/labquake_samples/sample_55.csv\n",
      "Batch 56 from both systems saved to example_data/labquake_samples/sample_56.csv\n",
      "Batch 57 from both systems saved to example_data/labquake_samples/sample_57.csv\n",
      "Batch 58 from both systems saved to example_data/labquake_samples/sample_58.csv\n",
      "Batch 59 from both systems saved to example_data/labquake_samples/sample_59.csv\n",
      "Batch 60 from both systems saved to example_data/labquake_samples/sample_60.csv\n",
      "Batch 61 from both systems saved to example_data/labquake_samples/sample_61.csv\n",
      "Batch 62 from both systems saved to example_data/labquake_samples/sample_62.csv\n",
      "Batch 63 from both systems saved to example_data/labquake_samples/sample_63.csv\n",
      "Batch 64 from both systems saved to example_data/labquake_samples/sample_64.csv\n",
      "Batch 65 from both systems saved to example_data/labquake_samples/sample_65.csv\n",
      "Batch 66 from both systems saved to example_data/labquake_samples/sample_66.csv\n",
      "Batch 67 from both systems saved to example_data/labquake_samples/sample_67.csv\n",
      "Batch 68 from both systems saved to example_data/labquake_samples/sample_68.csv\n",
      "Batch 69 from both systems saved to example_data/labquake_samples/sample_69.csv\n",
      "Batch 70 from both systems saved to example_data/labquake_samples/sample_70.csv\n",
      "Batch 71 from both systems saved to example_data/labquake_samples/sample_71.csv\n",
      "Batch 72 from both systems saved to example_data/labquake_samples/sample_72.csv\n",
      "Batch 73 from both systems saved to example_data/labquake_samples/sample_73.csv\n",
      "Batch 74 from both systems saved to example_data/labquake_samples/sample_74.csv\n",
      "Batch 75 from both systems saved to example_data/labquake_samples/sample_75.csv\n",
      "Batch 76 from both systems saved to example_data/labquake_samples/sample_76.csv\n",
      "Batch 77 from both systems saved to example_data/labquake_samples/sample_77.csv\n",
      "Batch 78 from both systems saved to example_data/labquake_samples/sample_78.csv\n",
      "Batch 79 from both systems saved to example_data/labquake_samples/sample_79.csv\n",
      "Batch 80 from both systems saved to example_data/labquake_samples/sample_80.csv\n",
      "Batch 81 from both systems saved to example_data/labquake_samples/sample_81.csv\n",
      "Batch 82 from both systems saved to example_data/labquake_samples/sample_82.csv\n",
      "Batch 83 from both systems saved to example_data/labquake_samples/sample_83.csv\n",
      "Batch 84 from both systems saved to example_data/labquake_samples/sample_84.csv\n",
      "Batch 85 from both systems saved to example_data/labquake_samples/sample_85.csv\n",
      "Batch 86 from both systems saved to example_data/labquake_samples/sample_86.csv\n",
      "Batch 87 from both systems saved to example_data/labquake_samples/sample_87.csv\n",
      "Batch 88 from both systems saved to example_data/labquake_samples/sample_88.csv\n",
      "Batch 89 from both systems saved to example_data/labquake_samples/sample_89.csv\n",
      "Batch 90 from both systems saved to example_data/labquake_samples/sample_90.csv\n",
      "Batch 91 from both systems saved to example_data/labquake_samples/sample_91.csv\n",
      "Batch 92 from both systems saved to example_data/labquake_samples/sample_92.csv\n",
      "Batch 93 from both systems saved to example_data/labquake_samples/sample_93.csv\n",
      "Batch 94 from both systems saved to example_data/labquake_samples/sample_94.csv\n",
      "Batch 95 from both systems saved to example_data/labquake_samples/sample_95.csv\n",
      "Batch 96 from both systems saved to example_data/labquake_samples/sample_96.csv\n",
      "Batch 97 from both systems saved to example_data/labquake_samples/sample_97.csv\n",
      "Batch 98 from both systems saved to example_data/labquake_samples/sample_98.csv\n",
      "Batch 99 from both systems saved to example_data/labquake_samples/sample_99.csv\n",
      "Batch 100 from both systems saved to example_data/labquake_samples/sample_100.csv\n",
      "Batch 101 from both systems saved to example_data/labquake_samples/sample_101.csv\n",
      "Batch 102 from both systems saved to example_data/labquake_samples/sample_102.csv\n",
      "Batch 103 from both systems saved to example_data/labquake_samples/sample_103.csv\n",
      "Batch 104 from both systems saved to example_data/labquake_samples/sample_104.csv\n",
      "Batch 105 from both systems saved to example_data/labquake_samples/sample_105.csv\n",
      "Batch 106 from both systems saved to example_data/labquake_samples/sample_106.csv\n",
      "Batch 107 from both systems saved to example_data/labquake_samples/sample_107.csv\n",
      "Batch 108 from both systems saved to example_data/labquake_samples/sample_108.csv\n",
      "Batch 109 from both systems saved to example_data/labquake_samples/sample_109.csv\n",
      "Batch 110 from both systems saved to example_data/labquake_samples/sample_110.csv\n",
      "Batch 111 from both systems saved to example_data/labquake_samples/sample_111.csv\n",
      "Batch 112 from both systems saved to example_data/labquake_samples/sample_112.csv\n",
      "Batch 113 from both systems saved to example_data/labquake_samples/sample_113.csv\n",
      "Batch 114 from both systems saved to example_data/labquake_samples/sample_114.csv\n",
      "Batch 115 from both systems saved to example_data/labquake_samples/sample_115.csv\n",
      "Batch 116 from both systems saved to example_data/labquake_samples/sample_116.csv\n",
      "Batch 117 from both systems saved to example_data/labquake_samples/sample_117.csv\n",
      "Batch 118 from both systems saved to example_data/labquake_samples/sample_118.csv\n",
      "Batch 119 from both systems saved to example_data/labquake_samples/sample_119.csv\n",
      "Batch 120 from both systems saved to example_data/labquake_samples/sample_120.csv\n",
      "Batch 121 from both systems saved to example_data/labquake_samples/sample_121.csv\n",
      "Batch 122 from both systems saved to example_data/labquake_samples/sample_122.csv\n",
      "Batch 123 from both systems saved to example_data/labquake_samples/sample_123.csv\n",
      "Batch 124 from both systems saved to example_data/labquake_samples/sample_124.csv\n",
      "Batch 125 from both systems saved to example_data/labquake_samples/sample_125.csv\n",
      "Batch 126 from both systems saved to example_data/labquake_samples/sample_126.csv\n",
      "Batch 127 from both systems saved to example_data/labquake_samples/sample_127.csv\n",
      "Batch 128 from both systems saved to example_data/labquake_samples/sample_128.csv\n",
      "Batch 129 from both systems saved to example_data/labquake_samples/sample_129.csv\n",
      "Batch 130 from both systems saved to example_data/labquake_samples/sample_130.csv\n",
      "Batch 131 from both systems saved to example_data/labquake_samples/sample_131.csv\n",
      "Batch 132 from both systems saved to example_data/labquake_samples/sample_132.csv\n",
      "Batch 133 from both systems saved to example_data/labquake_samples/sample_133.csv\n",
      "Batch 134 from both systems saved to example_data/labquake_samples/sample_134.csv\n",
      "Batch 135 from both systems saved to example_data/labquake_samples/sample_135.csv\n",
      "Batch 136 from both systems saved to example_data/labquake_samples/sample_136.csv\n",
      "Batch 137 from both systems saved to example_data/labquake_samples/sample_137.csv\n",
      "Batch 138 from both systems saved to example_data/labquake_samples/sample_138.csv\n",
      "Batch 139 from both systems saved to example_data/labquake_samples/sample_139.csv\n",
      "Batch 140 from both systems saved to example_data/labquake_samples/sample_140.csv\n",
      "Batch 141 from both systems saved to example_data/labquake_samples/sample_141.csv\n",
      "Batch 142 from both systems saved to example_data/labquake_samples/sample_142.csv\n",
      "Batch 143 from both systems saved to example_data/labquake_samples/sample_143.csv\n",
      "Batch 144 from both systems saved to example_data/labquake_samples/sample_144.csv\n",
      "Batch 145 from both systems saved to example_data/labquake_samples/sample_145.csv\n",
      "Batch 146 from both systems saved to example_data/labquake_samples/sample_146.csv\n",
      "Batch 147 from both systems saved to example_data/labquake_samples/sample_147.csv\n",
      "Batch 148 from both systems saved to example_data/labquake_samples/sample_148.csv\n",
      "Batch 149 from both systems saved to example_data/labquake_samples/sample_149.csv\n",
      "Batch 150 from both systems saved to example_data/labquake_samples/sample_150.csv\n",
      "Batch 151 from both systems saved to example_data/labquake_samples/sample_151.csv\n",
      "Batch 152 from both systems saved to example_data/labquake_samples/sample_152.csv\n",
      "Batch 153 from both systems saved to example_data/labquake_samples/sample_153.csv\n",
      "Batch 154 from both systems saved to example_data/labquake_samples/sample_154.csv\n",
      "Batch 155 from both systems saved to example_data/labquake_samples/sample_155.csv\n",
      "Batch 156 from both systems saved to example_data/labquake_samples/sample_156.csv\n",
      "Batch 157 from both systems saved to example_data/labquake_samples/sample_157.csv\n",
      "Batch 158 from both systems saved to example_data/labquake_samples/sample_158.csv\n",
      "Batch 159 from both systems saved to example_data/labquake_samples/sample_159.csv\n",
      "Batch 160 from both systems saved to example_data/labquake_samples/sample_160.csv\n",
      "Batch 161 from both systems saved to example_data/labquake_samples/sample_161.csv\n",
      "Batch 162 from both systems saved to example_data/labquake_samples/sample_162.csv\n",
      "Batch 163 from both systems saved to example_data/labquake_samples/sample_163.csv\n",
      "Batch 164 from both systems saved to example_data/labquake_samples/sample_164.csv\n",
      "Batch 165 from both systems saved to example_data/labquake_samples/sample_165.csv\n",
      "Batch 166 from both systems saved to example_data/labquake_samples/sample_166.csv\n",
      "Batch 167 from both systems saved to example_data/labquake_samples/sample_167.csv\n",
      "Batch 168 from both systems saved to example_data/labquake_samples/sample_168.csv\n",
      "Batch 169 from both systems saved to example_data/labquake_samples/sample_169.csv\n",
      "Batch 170 from both systems saved to example_data/labquake_samples/sample_170.csv\n",
      "Batch 171 from both systems saved to example_data/labquake_samples/sample_171.csv\n",
      "Batch 172 from both systems saved to example_data/labquake_samples/sample_172.csv\n",
      "Batch 173 from both systems saved to example_data/labquake_samples/sample_173.csv\n",
      "Batch 174 from both systems saved to example_data/labquake_samples/sample_174.csv\n",
      "Batch 175 from both systems saved to example_data/labquake_samples/sample_175.csv\n",
      "Batch 176 from both systems saved to example_data/labquake_samples/sample_176.csv\n",
      "Batch 177 from both systems saved to example_data/labquake_samples/sample_177.csv\n",
      "Batch 178 from both systems saved to example_data/labquake_samples/sample_178.csv\n",
      "All ground truth labels saved to example_data/labquake_samples/all_class_labels.csv\n"
     ]
    }
   ],
   "source": [
    "datamanager.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f325c6-b1c5-41ca-8892-98ff7f1369ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of CSV files with growing 'n'\n",
    "#num_files = 270  # specify the number of files\n",
    "#column_name = 'Channel_13'  # specify the column to plot\n",
    "#\n",
    "## Initialize plot\n",
    "#plt.figure(figsize=(15,5))\n",
    "#\n",
    "## Initialize the starting index for plotting\n",
    "#start_index = 0\n",
    "#\n",
    "## Loop over the files\n",
    "#for n in range(1, num_files + 1):\n",
    "#    # Construct file name\n",
    "#    file_name = f'example_data/labquake_samples/sample_{n}.csv'\n",
    "#    \n",
    "#    # Read CSV file\n",
    "#    df = pd.read_csv(file_name)\n",
    "#    \n",
    "#    # Get the length of the current column\n",
    "#    column_length = len(df[column_name])\n",
    "#    \n",
    "#    # Create a new index range that continues from where the last one left off\n",
    "#    index_range = range(start_index, start_index + column_length)\n",
    "#    \n",
    "#    # Plot the column from each CSV file using the new index range\n",
    "#    plt.plot(index_range, df[column_name])\n",
    "#    \n",
    "#    # Update the start_index for the next file\n",
    "#    start_index += column_length\n",
    "#\n",
    "## Add labels and title (no legend)\n",
    "#plt.xlabel('Index')\n",
    "#plt.ylabel('Value')\n",
    "#plt.title(f'Plot of {column_name} across multiple files')\n",
    "#\n",
    "## Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f81b2c-4c64-4db5-a8a0-ff4d6e75a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csv_row_sizes(directory):\n",
    "    # List all CSV files in the specified directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    \n",
    "    # Dictionary to store file names and their respective row counts\n",
    "    row_sizes = {}\n",
    "    \n",
    "    # Iterate over each file, read it with pandas, and get the number of rows\n",
    "    for file_name in csv_files:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            row_sizes[file_name] = len(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "    \n",
    "    # Print row counts for each file\n",
    "    for file_name, count in row_sizes.items():\n",
    "        print(f\"{file_name}: {count} rows\")\n",
    "\n",
    "# Example usage:\n",
    "#directory_path = params['samples_path']\n",
    "#check_csv_row_sizes(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97a9335-d779-4696-988a-d8ae86723134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_negative_moving_average_derivatives(dataset, window_size):\n",
    "    \"\"\"\n",
    "    Computes the negative of the moving average derivatives for the entire dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.Tensor): Input dataset, shape (batch_size, time_steps, num_features)\n",
    "        window_size (int): Window size for the moving average filter.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Negative moving average derivatives, shape (batch_size, time_steps, num_features)\n",
    "    \"\"\"\n",
    "    batch_size, time_steps, num_features = dataset.shape\n",
    "    all_negative_derivatives = []\n",
    "\n",
    "    # Instantiate a temporary RateEncoder to use its moving_average method\n",
    "    temp_encoder = RateEncoder(min_values=None, max_values=None, window_size=window_size)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sample_negative_derivatives = []\n",
    "        for j in range(num_features):\n",
    "            sample = dataset[i][:, j]  # Shape: (time_steps,)\n",
    "\n",
    "            # Compute derivative with same size\n",
    "            derivative = torch.zeros_like(sample)\n",
    "            derivative[1:] = sample[1:] - sample[:-1]\n",
    "            derivative[0] = 0  # Handle as appropriate\n",
    "\n",
    "            # Apply moving average\n",
    "            smoothed_derivative = temp_encoder.moving_average(derivative)\n",
    "\n",
    "            # Take the negative of the smoothed derivative\n",
    "            negative_derivative = -smoothed_derivative\n",
    "\n",
    "            sample_negative_derivatives.append(negative_derivative)\n",
    "\n",
    "        sample_negative_derivatives = torch.stack(sample_negative_derivatives, dim=1)  # Shape: (time_steps, num_features)\n",
    "        all_negative_derivatives.append(sample_negative_derivatives)\n",
    "\n",
    "    all_negative_derivatives = torch.stack(all_negative_derivatives, dim=0)  # Shape: (batch_size, time_steps, num_features)\n",
    "    return all_negative_derivatives\n",
    "\n",
    "def compute_thresholds(negative_derivatives, percentile):\n",
    "    \"\"\"\n",
    "    Computes thresholds for each feature based on the given percentile of the negative derivatives.\n",
    "\n",
    "    Args:\n",
    "        negative_derivatives (torch.Tensor): Negative moving average derivatives, shape (num_samples, num_features)\n",
    "        percentile (float): Percentile value (between 0 and 100) to compute thresholds.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Thresholds for each feature, shape (num_features,)\n",
    "    \"\"\"\n",
    "    # Convert to numpy array for percentile computation\n",
    "    negative_derivatives_np = negative_derivatives.numpy()\n",
    "\n",
    "    thresholds = []\n",
    "    for i in range(negative_derivatives_np.shape[1]):\n",
    "        feature_data = negative_derivatives_np[:, i]\n",
    "        threshold = np.percentile(feature_data, percentile)\n",
    "        thresholds.append(threshold)\n",
    "    thresholds = torch.tensor(thresholds)\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8ec8aa-8d2f-4650-9e42-cea802344242",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameslist = ['sample_'+str(idx)+'.csv' for idx in range(1,179)]\n",
    "\n",
    "dfs = []\n",
    "for filename in filenameslist:\n",
    "  dfs.append(pd.read_csv('./example_data/labquake_samples/'+filename, header=0))\n",
    "\n",
    "fulldf = pd.concat(dfs)\n",
    "\n",
    "# Load the CSV file\n",
    "labels = pd.read_csv('./example_data/labquake_samples/all_class_labels.csv')\n",
    "\n",
    "# Extract each column into a separate 1D array\n",
    "y1 = labels['Zone1'].values\n",
    "y2 = labels['Zone2'].values\n",
    "y3 = labels['Zone3'].values\n",
    "y4 = labels['Zone4'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79515db9-d68c-46a1-aa0e-6caee969b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance for Zone 1:\n",
      "  Class 0: 58 samples, 32.58%\n",
      "  Class 1: 120 samples, 67.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 1, Fold 1:\n",
      "  Class 0: 46 samples, 32.39%\n",
      "  Class 1: 96 samples, 67.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 1it [00:14, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 1, Fold 2:\n",
      "  Class 0: 45 samples, 31.69%\n",
      "  Class 1: 97 samples, 68.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 2it [00:28, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 1, Fold 3:\n",
      "  Class 0: 46 samples, 32.39%\n",
      "  Class 1: 96 samples, 67.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 3it [00:43, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 1, Fold 4:\n",
      "  Class 0: 45 samples, 31.47%\n",
      "  Class 1: 98 samples, 68.53%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 4it [00:57, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 1, Fold 5:\n",
      "  Class 0: 50 samples, 34.97%\n",
      "  Class 1: 93 samples, 65.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 1: 5it [01:12, 14.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Zone 1:\n",
      "Accuracy: 0.7359550561797753\n",
      "Confusion Matrix:\n",
      "[[ 27  31]\n",
      " [ 16 104]]\n",
      "\n",
      "Class balance for Zone 2:\n",
      "  Class 0: 92 samples, 51.69%\n",
      "  Class 1: 86 samples, 48.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 2, Fold 1:\n",
      "  Class 0: 77 samples, 54.23%\n",
      "  Class 1: 65 samples, 45.77%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 1it [00:14, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 2, Fold 2:\n",
      "  Class 0: 72 samples, 50.70%\n",
      "  Class 1: 70 samples, 49.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 2it [00:28, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 2, Fold 3:\n",
      "  Class 0: 73 samples, 51.41%\n",
      "  Class 1: 69 samples, 48.59%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 3it [00:43, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 2, Fold 4:\n",
      "  Class 0: 70 samples, 48.95%\n",
      "  Class 1: 73 samples, 51.05%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 4it [00:57, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 2, Fold 5:\n",
      "  Class 0: 76 samples, 53.15%\n",
      "  Class 1: 67 samples, 46.85%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 2: 5it [01:11, 14.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Zone 2:\n",
      "Accuracy: 0.6573033707865169\n",
      "Confusion Matrix:\n",
      "[[57 35]\n",
      " [26 60]]\n",
      "\n",
      "Class balance for Zone 3:\n",
      "  Class 0: 148 samples, 83.15%\n",
      "  Class 1: 30 samples, 16.85%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 3, Fold 1:\n",
      "  Class 0: 116 samples, 81.69%\n",
      "  Class 1: 26 samples, 18.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 1it [00:14, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 3, Fold 2:\n",
      "  Class 0: 119 samples, 83.80%\n",
      "  Class 1: 23 samples, 16.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 2it [00:28, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 3, Fold 3:\n",
      "  Class 0: 121 samples, 85.21%\n",
      "  Class 1: 21 samples, 14.79%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 3it [00:43, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 3, Fold 4:\n",
      "  Class 0: 120 samples, 83.92%\n",
      "  Class 1: 23 samples, 16.08%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 4it [00:57, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 3, Fold 5:\n",
      "  Class 0: 116 samples, 81.12%\n",
      "  Class 1: 27 samples, 18.88%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 3: 5it [01:11, 14.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Zone 3:\n",
      "Accuracy: 0.8314606741573034\n",
      "Confusion Matrix:\n",
      "[[145   3]\n",
      " [ 27   3]]\n",
      "\n",
      "Class balance for Zone 4:\n",
      "  Class 0: 89 samples, 50.00%\n",
      "  Class 1: 89 samples, 50.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 4, Fold 1:\n",
      "  Class 0: 75 samples, 52.82%\n",
      "  Class 1: 67 samples, 47.18%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 1it [00:14, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 4, Fold 2:\n",
      "  Class 0: 69 samples, 48.59%\n",
      "  Class 1: 73 samples, 51.41%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 2it [00:28, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 4, Fold 3:\n",
      "  Class 0: 71 samples, 50.00%\n",
      "  Class 1: 71 samples, 50.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 3it [00:43, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 4, Fold 4:\n",
      "  Class 0: 68 samples, 47.55%\n",
      "  Class 1: 75 samples, 52.45%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 4it [00:57, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training set for Zone 4, Fold 5:\n",
      "  Class 0: 73 samples, 51.05%\n",
      "  Class 1: 70 samples, 48.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zone 4: 5it [01:11, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Zone 4:\n",
      "Accuracy: 0.6966292134831461\n",
      "Confusion Matrix:\n",
      "[[60 29]\n",
      " [25 64]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assume the necessary functions and classes are defined:\n",
    "# compute_negative_moving_average_derivatives, compute_thresholds,\n",
    "# Deltav2, Reservoir, DeSNN, Pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "X = torch.tensor(fulldf.values.reshape(178, 900, 25))  # Adjust dimensions as per your dataset\n",
    "\n",
    "# Compute negative moving average derivatives\n",
    "negative_moving_avg_derivatives = compute_negative_moving_average_derivatives(X, window_size=10)\n",
    "\n",
    "# Reshape to a 2D tensor for percentile computation\n",
    "reshaped_negative_derivatives = negative_moving_avg_derivatives.view(-1, X.shape[2])  # Shape: (batch_size * time_steps, num_features)\n",
    "\n",
    "# Compute thresholds for each feature at the desired percentile (e.g., 90th percentile)\n",
    "percentile_value = 90.0  # Change as needed\n",
    "thresholds = compute_thresholds(reshaped_negative_derivatives, percentile=percentile_value)\n",
    "\n",
    "# Initialize your encoder\n",
    "encoder = Deltav2(thresholds)\n",
    "encoded_dataset = encoder.encode_dataset(X)\n",
    "\n",
    "# Load labels\n",
    "labels = pd.read_csv('./example_data/labquake_samples/all_class_labels.csv')\n",
    "ys = [labels[col].values for col in labels]  # Extract each column into a list of arrays\n",
    "\n",
    "# Set up K-Folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = {}\n",
    "\n",
    "for y_idx, y in enumerate(ys, start=1):\n",
    "    # Compute overall class balance for the current Zone\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    total_samples = len(y)\n",
    "    print(f\"Class balance for Zone {y_idx}:\")\n",
    "    for cls, count in zip(classes, counts):\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"  Class {cls}: {count} samples, {percentage:.2f}%\")\n",
    "    print()\n",
    "\n",
    "    y_total, pred_total = [], []\n",
    "\n",
    "    # Enumerate folds to keep track of fold number\n",
    "    for fold_num, (train_index, test_index) in enumerate(tqdm(kf.split(X), desc=f'Zone {y_idx}'), start=1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Compute class balance in the training set for the current fold\n",
    "        classes_fold, counts_fold = np.unique(y_train, return_counts=True)\n",
    "        total_samples_fold = len(y_train)\n",
    "        print(f\"Class balance in training set for Zone {y_idx}, Fold {fold_num}:\")\n",
    "        for cls, count in zip(classes_fold, counts_fold):\n",
    "            percentage = (count / total_samples_fold) * 100\n",
    "            print(f\"  Class {cls}: {count} samples, {percentage:.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Proceed with model training and testing\n",
    "        res = Reservoir(inputs=25)\n",
    "        # sam = SpikeCount()\n",
    "        sam = DeSNN()\n",
    "        clf = LogisticRegression(solver='liblinear')\n",
    "        pipe = Pipeline(res, sam, clf)\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        pred = pipe.predict(X_test)\n",
    "\n",
    "        y_total.extend(y_test)\n",
    "        pred_total.extend(pred)\n",
    "\n",
    "    # Compute overall accuracy and confusion matrix for the current Zone\n",
    "    acc = accuracy_score(y_total, pred_total)\n",
    "    cm = confusion_matrix(y_total, pred_total)\n",
    "    results[f'Zone {y_idx}'] = {'accuracy': acc, 'confusion_matrix': cm}\n",
    "    print(f\"Results for Zone {y_idx}:\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea4223-1a30-47ef-a82c-6f079c8f1c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
